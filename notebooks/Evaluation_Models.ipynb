{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# # Plotting evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from relnet.agent.baseline.baseline_agent import *\n",
    "from relnet.agent.rnet_dqn.rnet_dqn_agent import RNetDQNAgent\n",
    "from relnet.agent.supervised.sl_agent import SLAgent\n",
    "\n",
    "from relnet.evaluation.storage import EvaluationStorage\n",
    "from relnet.evaluation.experiment_conditions import *\n",
    "from relnet.evaluation.file_paths import FilePaths\n",
    "from relnet.visualization import *\n",
    "\n",
    "storage = EvaluationStorage()\n",
    "\n",
    "edge_percentages_considered = [1, 2.5, 5]\n",
    "L_values = [2, 5, 10]\n",
    "\n",
    "considered_agents = {RandomAgent.algorithm_name,\n",
    "                       GreedyAgent.algorithm_name,\n",
    "                       LowestDegreeProductAgent.algorithm_name,\n",
    "                       FiedlerVectorAgent.algorithm_name,\n",
    "                       EffectiveResistanceAgent.algorithm_name,\n",
    "                       RNetDQNAgent.algorithm_name,\n",
    "                       SLAgent.algorithm_name\n",
    "                       }\n",
    "considered_agents_models = [RNetDQNAgent.algorithm_name, SLAgent.algorithm_name]\n",
    "considered_agents_nondet = [RandomAgent.algorithm_name, RNetDQNAgent.algorithm_name, SLAgent.algorithm_name]\n",
    "\n",
    "cols_order = ['random', 'lowest_degree_product', 'fiedler_vector', 'effective_resistance', 'greedy', 'sl', 'sl_best', 'rnet_dqn', 'rnet_dqn_best', ]\n",
    "cols_order_plot = ['rnet_dqn', 'random', 'lowest_degree_product', 'fiedler_vector', 'effective_resistance', 'greedy', 'sl']\n",
    "\n",
    "fp = FilePaths('/experiment_data', 'aggregate')\n",
    "\n",
    "exp_ids = [storage.find_latest_experiment_id('model', percentage) for percentage in edge_percentages_considered]\n",
    "print(exp_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_result_dfs = []\n",
    "for i, exp_id in enumerate(exp_ids):\n",
    "    tau = edge_percentages_considered[i]\n",
    "    results = storage.get_evaluation_data('model', exp_id)\n",
    "    experiment_details = storage.get_experiment_details('model', exp_id)\n",
    "    network_sizes = [experiment_details['experiment_conditions']['base_n'] * mul for mul in experiment_details['experiment_conditions']['size_multipliers']]\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.head(5))\n",
    "\n",
    "    results_df = results_df[results_df['algorithm'].isin(considered_agents)]\n",
    "    results_df[\"tau\"] = [tau] * len(results_df)\n",
    "    all_result_dfs.append(results_df)\n",
    "\n",
    "all_results_df = pd.concat(all_result_dfs)\n",
    "all_results_df.sort_values(by=['objective_function', 'network_generator', 'tau'], inplace=True)\n",
    "all_results_df['algorithm'] = pd.Categorical(all_results_df['algorithm'], cols_order_plot)\n",
    "all_results_df.sort_values(\"algorithm\")\n",
    "main_fig_file = fp.figures_dir / f\"results_evaluation_models.pdf\"\n",
    "plot_size_based_results(all_results_df, main_fig_file, network_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting evaluation curves for trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_hyperparam_combinations(agent_name, obj_fun_name):\n",
    "    experiment_details = storage.get_experiment_details('model', exp_ids[0])\n",
    "    agent_grid = experiment_details['experiment_conditions']['hyperparam_grids'][obj_fun_name][agent_name]\n",
    "    num_hyperparam_combs = len(list(product(*agent_grid.values())))\n",
    "    return num_hyperparam_combs\n",
    "\n",
    "agent_name = RNetDQNAgent.algorithm_name\n",
    "\n",
    "exp_details = storage.get_experiment_details('model', exp_ids[0])\n",
    "objective_functions = exp_details['objective_functions']\n",
    "network_generators = exp_details['network_generators']\n",
    "num_hyperparam_combs = get_num_hyperparam_combinations(agent_name, objective_functions[0])\n",
    "\n",
    "\n",
    "for comb in range(num_hyperparam_combs):\n",
    "    for obj_fun_name in objective_functions:\n",
    "        all_data_dfs = []\n",
    "        for i, exp_id in enumerate(exp_ids):\n",
    "            L = L_values[i]\n",
    "            experiment_details = storage.get_experiment_details('model', exp_id)\n",
    "            network_generators = experiment_details['network_generators']\n",
    "            objective_functions = experiment_details['objective_functions']\n",
    "            fp_in = FilePaths('/experiment_data', exp_id)\n",
    "\n",
    "            experiment_conditions = experiment_details['experiment_conditions']\n",
    "            steps_used = experiment_conditions['agent_budgets'][obj_fun_name][agent_name]\n",
    "\n",
    "            model_seeds = experiment_conditions['experiment_params']['model_seeds']\n",
    "            print(f\"model seeds be {model_seeds}\")\n",
    "\n",
    "            # plot aggregate with CIs\n",
    "            data_df = storage.fetch_all_eval_curves(agent_name, comb, fp_in, experiment_details['objective_functions'],\n",
    "                                                            experiment_details['network_generators'],\n",
    "                                                            model_seeds,\n",
    "                                                            train_individually=False\n",
    "                                                            # tODO!!!!\n",
    "                                                        )\n",
    "            data_df[\"algorithm\"] = ''.join(ch for ch in exp_id if ch.isalnum())\n",
    "            data_df[\"L\"] = [L] * len(data_df)\n",
    "            max_steps_used = experiment_conditions[\"agent_budgets\"][obj_fun_name][agent_name]\n",
    "            data_df[\"max_steps_used\"] = [max_steps_used] * len(data_df)\n",
    "            data_df.sort_values(by=['network_generator', 'objective_function', 'L'], inplace=True)\n",
    "            all_data_dfs.append(data_df)\n",
    "\n",
    "    agg_df = pd.concat(all_data_dfs)\n",
    "    print(agg_df)\n",
    "    eval_plot_filename = f'eval_curves_all_seeds_{agent_name}_{comb}.pdf'\n",
    "\n",
    "    plot_eval_histories(agg_df, \n",
    "                        fp.figures_dir / eval_plot_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generating table of results -- several experiments, varying sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_result_dfs = []\n",
    "for i, exp_id in enumerate(exp_ids):\n",
    "    experiment_details = storage.get_experiment_details('model', exp_id)\n",
    "    L = L_values[i]\n",
    "\n",
    "    network_size = experiment_details['experiment_conditions']['base_n']\n",
    "    \n",
    "    results = storage.get_evaluation_data('model', exp_id)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_filtered = pd.DataFrame(results_df[results_df['network_size'] == network_size])\n",
    "    if considered_agents is not None:\n",
    "        results_filtered = results_filtered[results_filtered['algorithm'].isin(considered_agents)]\n",
    "    \n",
    "    results_filtered['L'] = [L] * len(results_filtered)\n",
    "    all_result_dfs.append(results_filtered)\n",
    "\n",
    "all_results_df = pd.concat(all_result_dfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ci(data, confidence=0.95):\n",
    "    a = np.array(data)\n",
    "    n = len(a)\n",
    "    se = sp.stats.sem(a)\n",
    "    h = se * sp.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "csv_results_file = fp.figures_dir / f\"results_evaluation_models.csv\"\n",
    "pivot = pd.pivot_table(all_results_df, values='cummulative_reward', \n",
    "                       columns=['algorithm'], \n",
    "                       index=['objective_function', 'network_generator', 'L'],\n",
    "                       aggfunc=np.mean)\n",
    "\n",
    "for model_agent in considered_agents_models:\n",
    "    model_agent_df = all_results_df[all_results_df['algorithm'] == model_agent]\n",
    "    maxcol = pd.pivot_table(model_agent_df, values='cummulative_reward',\n",
    "                           columns=['agent_seed'],\n",
    "                           index=['objective_function', 'network_generator', 'L'],\n",
    "                           aggfunc=np.mean)\n",
    "    maxes = maxcol.max(axis=1)\n",
    "    pivot[f\"{model_agent}_best\"] = maxes\n",
    "\n",
    "nondet_df = all_results_df[all_results_df['algorithm'].isin(considered_agents_nondet)]\n",
    "nondet_means_df = pd.pivot_table(nondet_df, values='cummulative_reward', \n",
    "                       columns=['algorithm', 'agent_seed'], \n",
    "                       index=['objective_function', 'network_generator', 'L'],                       \n",
    "                       aggfunc=np.mean)\n",
    "\n",
    "\n",
    "format_ci_dict = {}\n",
    "for agent_name in considered_agents_nondet:\n",
    "    cis = nondet_means_df[agent_name].apply(compute_ci, axis=1)\n",
    "    pivot[agent_name + \"_ci\"] = cis\n",
    "    format_ci_dict[agent_name + \"_ci\"] = (lambda x: \"±{:.3f}\".format(abs(x)))\n",
    "    \n",
    "pivot.to_csv(csv_results_file)\n",
    "pivot.style.apply(highlight_max, axis=1).format(\"{:.3f}\").format(format_ci_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latex_df = pivot.copy()\n",
    "for nondet_agent in considered_agents_nondet:\n",
    "    colname_ci = f\"{nondet_agent}_ci\"\n",
    "    latex_df[nondet_agent] = latex_df.agg(lambda x: f\"{x[nondet_agent]:.3f}±{x[colname_ci]:.3f}\", axis=1)\n",
    "    latex_df.drop(columns=[colname_ci], inplace=True)\n",
    "    \n",
    "latex_df = latex_df[cols_order]\n",
    "row_maxes = latex_df.max(axis=1)\n",
    "\n",
    "repl_cols = copy(agent_display_names)\n",
    "latex_df.rename(columns=repl_cols, inplace=True)\n",
    "texfile =  str(fp.figures_dir / f\"results_evaluation_models.tex\")\n",
    "fh = open(texfile, 'w')\n",
    "table_colformat = f\"ccc|{''.join(['c'] * len(cols_order)) }\"\n",
    "latex_df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, column_format=table_colformat)\n",
    "fh.close()\n",
    "\n",
    "\n",
    "\n",
    "replace_dict = {\n",
    "    r\"objective\\\\_function\": r\"Objective\",\n",
    "    r\"network\\\\_generator\" : r\"$\\\\mathbf{G}$\",\n",
    "    r\"algorithm\" : r\"\",\n",
    "    r\"RNet–DQN\\s+&\" : \"\\\\multicolumn{2}{c}{RNet–DQN}\",\n",
    "    r\"SL\\s+&\" : \"\\\\multicolumn{2}{c}{SL}\",\n",
    "    r\"rnet\\\\_dqn\\\\_best\" : r\"\",\n",
    "    r\"sl\\\\_best\" : r\"\",\n",
    "    r\"random\\\\_removal\": r\"$\\\\mathcal{F}_{random}$\",\n",
    "    r\"targeted\\\\_removal\": r\"$\\\\mathcal{F}_{targeted}$\",\n",
    "    r\"random\\\\_network\": r\"ER\",\n",
    "    r\"barabasi\\\\_albert\": r\"BA\",\n",
    "    r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\"\n",
    "}\n",
    "\n",
    "for row_max in row_maxes:\n",
    "    replace_key = fr\"{row_max:.3f}\"\n",
    "    replace_val = r\"\\\\textbf{\" + replace_key + \"}\"\n",
    "    replace_dict[replace_key] = replace_val\n",
    "\n",
    "with open(texfile, 'r') as f:\n",
    "    raw_content = f.read()\n",
    "\n",
    "processed_content = raw_content\n",
    "for orig, targ in replace_dict.items():\n",
    "    processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "    \n",
    "with open(texfile, 'w') as g:\n",
    "    g.write(processed_content)\n",
    "    \n",
    "with open(texfile, 'r') as f:\n",
    "    content_lines = f.readlines()\n",
    "    \n",
    "content_out = []    \n",
    "for i, line in enumerate(content_lines):\n",
    "    if i == 1 or i == (len(content_lines) - 2): \n",
    "        continue\n",
    "    if i == 3:\n",
    "        splits = line.split(\"&\")\n",
    "        splits[-4] = \" \\\\textit{avg}\"\n",
    "        splits[-3] = \" \\\\textit{best} \\\\\\\\\\n\"\n",
    "        splits[-2] = \" \\\\textit{avg}\"\n",
    "        splits[-1] = \" \\\\textit{best} \\\\\\\\\\n\"\n",
    "        content_out.append(\"&\".join(splits))\n",
    "        continue\n",
    "    \n",
    "    content_out.append(line)\n",
    "\n",
    "with open(texfile, 'w') as g:\n",
    "    g.write(\"\".join(content_out))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RelNET)",
   "language": "python",
   "name": "relnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}